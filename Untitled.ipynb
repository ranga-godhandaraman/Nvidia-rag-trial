{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a4ad0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Necessary for Colab, not necessary for course environment\n",
    "%pip install -q langchain langchain-nvidia-ai-endpoints gradio typing_extensions>=4.8.0\n",
    "\n",
    "## If you're in colab and encounter a typing-extensions issue,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c76205af",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  restart your runtime and try again\n",
    "from langchain_nvidia_ai_endpoints._common import NVEModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cca5570f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "import requests\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5087f658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA API Key: ········\n",
      "Retrieved NVIDIA_API_KEY beginning with \"nvapi-ZAj...\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'playground_nemotron_qa_8b': '0c60f14d-46cb-465e-b994-227e1c3d5047',\n",
       " 'playground_llama2_code_70b': '2ae529dc-f728-4a46-9b8d-2697213666d8',\n",
       " 'playground_yi_34b': '347fa3f3-d675-432c-b844-669ef8ee53df',\n",
       " 'playground_kosmos_2': '0bcd1a8c-451f-4b12-b7f0-64b4781190d1',\n",
       " 'playground_mistral_7b': '35ec3354-2681-4d0e-a8dd-80325dcf7c63',\n",
       " 'playground_gemma_2b': '5bde8f6f-7e83-4413-a0f2-7b97be33988e',\n",
       " 'playground_sdxl': '89848fb8-549f-41bb-88cb-95d6597044a4',\n",
       " 'playground_neva_22b': '8bf70738-59b9-4e5f-bc87-7ab4203be7a0',\n",
       " 'playground_mamba_chat': '381be320-4721-4664-bd75-58f8783b43c7',\n",
       " 'playground_gemma_7b': '1361fa56-61d7-4a12-af32-69a3825746fa',\n",
       " 'playground_deplot': '3bc390c7-eeec-40f7-a64d-0c6a719985f7',\n",
       " 'playground_cuopt': '8f2fbd00-2633-41ce-ab4e-e5736d74bff7',\n",
       " 'playground_llama2_13b': 'e0bb7fb9-5333-4a27-8534-c6288f921d3f',\n",
       " 'playground_llama2_code_13b': 'f6a96af4-8bf9-4294-96d6-d71aa787612e',\n",
       " 'playground_llama_guard': 'b34280ac-24e4-4081-bfaa-501e9ee16b6f',\n",
       " 'playground_starcoder2_15b': '6acada03-fe2f-4e4d-9e0a-e711b9fd1b59',\n",
       " 'playground_nvolveqa_40k': '091a03bb-7364-4087-8090-bd71e9277520',\n",
       " 'playground_nemotron_steerlm_8b': '1423ff2f-d1c7-4061-82a7-9e8c67afd43a',\n",
       " 'playground_seamless': '72ad9555-2e3d-4e73-9050-a37129064743',\n",
       " 'playground_llama2_70b': '0e349b44-440a-44e1-93e9-abe8dcb27158',\n",
       " 'playground_phi2': '6251d6d2-54ee-4486-90f4-2792bf0d3acd',\n",
       " 'playground_steerlm_llama_70b': 'd6fe6881-973a-4279-a0f8-e1d486c9618d',\n",
       " 'playground_fuyu_8b': '9f757064-657f-4c85-abd7-37a7a9b6ee11',\n",
       " 'playground_nv_llama2_rlhf_70b': '7b3e3361-4266-41c8-b312-f5e33c81fc92',\n",
       " 'playground_clip': '8c21289c-0b18-446d-8838-011b7249c513',\n",
       " 'playground_llama2_code_34b': 'df2bee43-fb69-42b9-9ee5-f4eabbeaf3a8',\n",
       " 'playground_mixtral_8x7b': '8f4118ba-60a8-4e6b-8574-e38a4067a4a3'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hard_reset = False  ## <-- Set to True if you want to reset your NVIDIA_API_KEY\n",
    "while \"nvapi-\" not in os.environ.get(\"NVIDIA_API_KEY\", \"\") or hard_reset:\n",
    "    try: \n",
    "        assert not hard_reset\n",
    "        response = requests.get(\"http://docker_router:8070/get_key\").json()\n",
    "        assert response.get('nvapi_key')\n",
    "    except: response = {'nvapi_key' : getpass(\"NVIDIA API Key: \")}\n",
    "    os.environ[\"NVIDIA_API_KEY\"] = response.get(\"nvapi_key\")\n",
    "    try: requests.post(\"http://docker_router:8070/set_key/\", json={'nvapi_key' : os.environ[\"NVIDIA_API_KEY\"]}).json()\n",
    "    except: pass\n",
    "    hard_reset = False\n",
    "    if \"nvapi-\" not in os.environ.get(\"NVIDIA_API_KEY\", \"\"):\n",
    "        print(\"[!] API key assignment failed. Make sure it starts with `nvapi-` as generated from the model pages.\")\n",
    "\n",
    "print(f\"Retrieved NVIDIA_API_KEY beginning with \\\"{os.environ.get('NVIDIA_API_KEY')[:9]}...\\\"\")\n",
    "from langchain_nvidia_ai_endpoints._common import NVEModel\n",
    "NVEModel().available_models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1d9705",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "<br>\n",
    "\n",
    "## **Part 2:** Chains and Runnables\n",
    "\n",
    "When exploring a new library, it's important to note what are the core systems of the library and how are they used.\n",
    "\n",
    "In LangChain, the main building block *used to be* the classic **Chain**: a small module of functionality that does something specific and can be linked up with other chains to make a system. So for all intents and purposes, it is a \"building-block system\" abstraction where the building blocks are easy to create, have consistent methods (`invoke`, `generate`, `stream`, etc), and can be linked up to work together as a system. Some example legacy chains include `LLMChain`, `ConversationChain`, `TransformationChain`, `SequentialChain`, etc.\n",
    "\n",
    "More recently, a new recommended specification has emerged that is significantly easier to work with and extremely compact, the **LangChain Expression Language (LCEL)**. This new format relies on a different kind of primitive - a **Runnable** - which is simply an object that wraps a function. Allow dictionaries to be implicitly converted to Runnables and let a **pipe |** operator create a Runnable that passes data from the left to the right (i.e. `fn1 | fn2` is a Runnable), and you have a simple way to specify complex logic!\n",
    "\n",
    "Here are some very representative example Runnables, created via the `RunnableLambda` class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03ccfb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.runnable import RunnableLambda, RunnablePassthrough\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ff0a0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "## Very simple \"take input and return it\"\n",
    "identity = RunnableLambda(lambda x: x)  ## Or RunnablePassthrough works\n",
    "\n",
    "################################################################################\n",
    "## Given an arbitrary function, you can make a runnable with it\n",
    "def print_and_return(x, preface=\"\"):\n",
    "    print(f\"{preface}{x}\")\n",
    "    return x\n",
    "\n",
    "rprint0 = RunnableLambda(print_and_return)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "202f18ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "## You can also pre-fill some of values using functools.partial\n",
    "rprint1 = RunnableLambda(partial(print_and_return, preface=\"1: \"))\n",
    "\n",
    "################################################################################\n",
    "## And you can use the same idea to make your own custom Runnable generator\n",
    "def RPrint(preface=\"\"):\n",
    "    return RunnableLambda(partial(print_and_return, preface=preface))\n",
    "\n",
    "################################################################################\n",
    "## Chaining two runnables\n",
    "chain1 = identity | rprint0\n",
    "chain1.invoke(\"Hello World!\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c157f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome Home!\n",
      "1: Welcome Home!\n",
      "2: Welcome Home!\n",
      "\n",
      "Output: Welcome Home!\n"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "## Chaining that one in as well\n",
    "output = (\n",
    "    chain1\n",
    "    | rprint1\n",
    "    | RPrint(\"2: \")\n",
    ").invoke(\"Welcome Home!\")\n",
    "\n",
    "print(\"\\nOutput:\", output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66bfb765",
   "metadata": {},
   "source": [
    "## Example with LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ffdc0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d3b1b356",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Simple Chat Pipeline\n",
    "chat_llm = ChatNVIDIA(model=\"llama2_13b\")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",), #\"Only respond in rhymes\" - rhym parameter\n",
    "    (\"user\", \"{input}\")\n",
    "])\n",
    "\n",
    "rhyme_chain = prompt | chat_llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1026826c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explainable AI (XAI) in healthcare is an emerging technology that aims to provide insights into the decision-making process of AI models, particularly in high-stakes applications such as diagnosis and treatment planning. While XAI has the potential to revolutionize healthcare by increasing trust and transparency, it also raises several ethical considerations and implementation challenges. In this response, I will outline the ethical considerations and implementation challenges of XAI in healthcare, and discuss how they can be addressed to foster trust and transparency in patient-centric decision-making.\n",
      "\n",
      "Ethical Considerations:\n",
      "\n",
      "1. Bias and Discrimination: AI models can perpetuate existing biases and discrimination in healthcare, particularly if they are trained on biased data. XAI must be designed to identify and mitigate these biases.\n",
      "2. Privacy and Security: XAI must ensure the privacy and security of patient data, particularly in cases where sensitive information is involved.\n",
      "3. Transparency and Interpretability: XAI must provide clear and understandable explanations of AI decisions, allowing patients and healthcare providers to understand the reasoning behind the recommendations.\n",
      "4. Accountability and Liability: As XAI becomes more prevalent in healthcare, there must be clear lines of accountability and liability for AI decisions, particularly in cases where errors or adverse events occur.\n",
      "5. Human-Centered Design: XAI must be designed with a human-centered approach, taking into account the needs and values of patients and healthcare providers.\n",
      "\n",
      "Implementation Challenges:\n",
      "\n",
      "1. Data Quality and Availability: XAI requires high-quality and abundant data to train and validate AI models. However, healthcare data can be fragmented, noisy, and difficult to obtain.\n",
      "2. Regulatory and Ethical Frameworks: There is a lack of regulatory and ethical frameworks for XAI in healthcare, which can make it difficult to ensure that XAI systems are safe and effective.\n",
      "3. Clinical Validation and Integration: XAI must be clinically validated and integrated into existing healthcare systems, which can be challenging due to the complexity of healthcare infrastructure and the need for interoperability.\n",
      "4. Human-AI Collaboration: XAI must be designed to facilitate effective collaboration between humans and AI systems, which can be challenging due to the differences in how humans and AI systems process information.\n",
      "5. Training and Education: Healthcare providers must be trained and educated on how to use XAI systems effectively, which can be time-consuming and resource-intensive.\n",
      "\n",
      "Addressing the Challenges:\n",
      "\n",
      "1. Collaboration and Partnerships: Stakeholders must collaborate and form partnerships to address the ethical considerations and implementation challenges of XAI in healthcare. This includes patients, healthcare providers, AI developers, and regulatory agencies.\n",
      "2. Investment in Data Infrastructure: There must be investment in data infrastructure to improve the quality and availability of healthcare data, particularly in underserved communities.\n",
      "3. Development of Regulatory and Ethical Frameworks: Regulatory and ethical frameworks must be developed to ensure that XAI systems are safe and effective, and that they are aligned with human values and societal norms.\n",
      "4. Human-Centered Design: XAI systems must be designed with a human-centered approach, taking into account the needs and values of patients and healthcare providers.\n",
      "5. Education and Training: Healthcare providers must be trained and educated on how to use XAI systems effectively, and patients must be educated on how to use XAI systems to make informed decisions about their healthcare.\n",
      "\n",
      "In conclusion, XAI has the potential to revolutionize healthcare by increasing trust and transparency in patient-centric decision-making. However, there are several ethical considerations and implementation challenges that must be addressed to ensure that XAI systems are safe, effective, and aligned with human values and societal norms. By collaborating and forming partnerships, investing in data infrastructure, developing regulatory and ethical frameworks, using a human-centered design approach, and providing education and training, we can foster trust and transparency in patient-centric decision-making and improve healthcare outcomes for all.\n"
     ]
    }
   ],
   "source": [
    "print(rhyme_chain.invoke({\"input\" : \"explain Ethical Considerations and Implementation Challenges of Explainable AI in Healthcare: Fostering Trust and Transparency in Patient Centric Decision-making \"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8750a29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "Running on public URL: https://d3393d1f03df292760.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://d3393d1f03df292760.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "#######################################################\n",
    "## Non-streaming Interface like that shown above\n",
    "\n",
    "# def rhyme_chat(message, history):\n",
    "#     return rhyme_chain.invoke({\"input\" : message})\n",
    "\n",
    "# gr.ChatInterface(rhyme_chat).launch()\n",
    "\n",
    "#######################################################\n",
    "## Streaming Interface\n",
    "\n",
    "def rhyme_chat_stream(message, history):\n",
    "    ## This is a generator function, where each call will yield the next entry\n",
    "    buffer = \"\"\n",
    "    for token in rhyme_chain.stream({\"input\" : message}):\n",
    "        buffer += token\n",
    "        yield buffer\n",
    "\n",
    "## Uncomment when you're ready to try this. IF USING COLAB: Share=False is faster\n",
    "gr.ChatInterface(rhyme_chat_stream).queue().launch(share=True, debug=True) \n",
    "\n",
    "## NOTE: When you're done, please click the Square button (twice to be safe) to stop the session."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76677f9a",
   "metadata": {},
   "source": [
    "## Example 2: Internal Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b24689e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "## TODO: Try out some more models and see if there are better options\n",
    "instruct_llm = ChatNVIDIA(model=\"llama2_13b\")\n",
    "\n",
    "## Zero-shot classification prompt and chain\n",
    "zsc_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", (\n",
    "        \"Pick the most likely topic of the sentence. Choose an one option of the following: {options}. Only one word-answers\"\n",
    "    )),\n",
    "    (\"user\", \"[Options : {options}] {input} = \")\n",
    "])\n",
    "\n",
    "zsc_chain = zsc_prompt | instruct_llm | StrOutputParser()\n",
    "\n",
    "def zsc_call(input, options=[\"car\", \"boat\", \"airplane\", \"bike\"]):\n",
    "    return zsc_chain.invoke({\"input\" : input, \"options\" : options})\n",
    "\n",
    "print(\"-\" * 80)\n",
    "print(zsc_call(\"Should I take the next exit, or keep going to the next one?\"))\n",
    "\n",
    "print(\"-\" * 80)\n",
    "print(zsc_call(\"I get seasick, so I think I'll pass on the trip\"))\n",
    "\n",
    "print(\"-\" * 80)\n",
    "print(zsc_call(\"I'm scared of heights, so flying probably isn't for me\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ff2bf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6398f609",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4346fe39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
