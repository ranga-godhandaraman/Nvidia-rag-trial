{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ac09f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA API Key: ········\n",
      "Retrieved NVIDIA_API_KEY beginning with \"nvapi-ZAj...\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'playground_kosmos_2': '0bcd1a8c-451f-4b12-b7f0-64b4781190d1',\n",
       " 'playground_nemotron_qa_8b': '0c60f14d-46cb-465e-b994-227e1c3d5047',\n",
       " 'playground_gemma_7b': '1361fa56-61d7-4a12-af32-69a3825746fa',\n",
       " 'playground_llama2_code_70b': '2ae529dc-f728-4a46-9b8d-2697213666d8',\n",
       " 'playground_llama2_70b': '0e349b44-440a-44e1-93e9-abe8dcb27158',\n",
       " 'playground_nemotron_steerlm_8b': '1423ff2f-d1c7-4061-82a7-9e8c67afd43a',\n",
       " 'playground_phi2': '6251d6d2-54ee-4486-90f4-2792bf0d3acd',\n",
       " 'playground_mamba_chat': '381be320-4721-4664-bd75-58f8783b43c7',\n",
       " 'playground_deplot': '3bc390c7-eeec-40f7-a64d-0c6a719985f7',\n",
       " 'playground_starcoder2_15b': '6acada03-fe2f-4e4d-9e0a-e711b9fd1b59',\n",
       " 'playground_sdxl': '89848fb8-549f-41bb-88cb-95d6597044a4',\n",
       " 'playground_nv_llama2_rlhf_70b': '7b3e3361-4266-41c8-b312-f5e33c81fc92',\n",
       " 'playground_neva_22b': '8bf70738-59b9-4e5f-bc87-7ab4203be7a0',\n",
       " 'playground_clip': '8c21289c-0b18-446d-8838-011b7249c513',\n",
       " 'playground_fuyu_8b': '9f757064-657f-4c85-abd7-37a7a9b6ee11',\n",
       " 'playground_mixtral_8x7b': '8f4118ba-60a8-4e6b-8574-e38a4067a4a3',\n",
       " 'playground_llama_guard': 'b34280ac-24e4-4081-bfaa-501e9ee16b6f',\n",
       " 'playground_llama2_13b': 'e0bb7fb9-5333-4a27-8534-c6288f921d3f',\n",
       " 'playground_steerlm_llama_70b': 'd6fe6881-973a-4279-a0f8-e1d486c9618d',\n",
       " 'playground_llama2_code_13b': 'f6a96af4-8bf9-4294-96d6-d71aa787612e',\n",
       " 'playground_llama2_code_34b': 'df2bee43-fb69-42b9-9ee5-f4eabbeaf3a8',\n",
       " 'playground_yi_34b': '347fa3f3-d675-432c-b844-669ef8ee53df',\n",
       " 'playground_nvolveqa_40k': '091a03bb-7364-4087-8090-bd71e9277520',\n",
       " 'playground_mistral_7b': '35ec3354-2681-4d0e-a8dd-80325dcf7c63',\n",
       " 'playground_seamless': '72ad9555-2e3d-4e73-9050-a37129064743',\n",
       " 'playground_cuopt': '8f2fbd00-2633-41ce-ab4e-e5736d74bff7',\n",
       " 'playground_gemma_2b': '5bde8f6f-7e83-4413-a0f2-7b97be33988e'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from getpass import getpass\n",
    "import requests\n",
    "import os\n",
    "\n",
    "hard_reset = False  ## <-- Set to True if you want to reset your NVIDIA_API_KEY\n",
    "while \"nvapi-\" not in os.environ.get(\"NVIDIA_API_KEY\", \"\") or hard_reset:\n",
    "    try: \n",
    "        assert not hard_reset\n",
    "        response = requests.get(\"http://docker_router:8070/get_key\").json()\n",
    "        assert response.get('nvapi_key')\n",
    "    except: response = {'nvapi_key' : getpass(\"NVIDIA API Key: \")}\n",
    "    os.environ[\"NVIDIA_API_KEY\"] = response.get(\"nvapi_key\")\n",
    "    try: requests.post(\"http://docker_router:8070/set_key/\", json={'nvapi_key' : os.environ[\"NVIDIA_API_KEY\"]}).json()\n",
    "    except: pass\n",
    "    hard_reset = False\n",
    "    if \"nvapi-\" not in os.environ.get(\"NVIDIA_API_KEY\", \"\"):\n",
    "        print(\"[!] API key assignment failed. Make sure it starts with `nvapi-` as generated from the model pages.\")\n",
    "\n",
    "print(f\"Retrieved NVIDIA_API_KEY beginning with \\\"{os.environ.get('NVIDIA_API_KEY')[:9]}...\\\"\")\n",
    "from langchain_nvidia_ai_endpoints._common import NVEModel\n",
    "NVEModel().available_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033803fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade --quiet  arxiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e041690c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade --quiet  pymupdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e48a0b",
   "metadata": {},
   "source": [
    "## Part 1: Chatting with Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9261a6f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 367 ms, sys: 499 ms, total: 865 ms\n",
      "Wall time: 5.91 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from langchain.document_loaders import UnstructuredFileLoader\n",
    "from langchain.document_loaders import ArxivLoader\n",
    "\n",
    "## Loading in the file\n",
    "\n",
    "## Unstructured File Loader: Good for arbitrary \"probably good enough\" loader\n",
    "# documents = UnstructuredFileLoader(\"llama2_paper.pdf\").load()\n",
    "\n",
    "## More specialized loader, won't work for everything, but simple API and usually better results\n",
    "documents = ArxivLoader(query=\"2205.00445\").load()  ## MRKL\n",
    "# documents = ArxivLoader(query=\"2210.03629\").load()  ## ReAct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7369d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Documents Retrieved: 1\n",
      "Sample of Document 1 Content (Total Length: 36261):\n",
      "MRKL Systems\n",
      "A modular, neuro-symbolic architecture that combines large language\n",
      "models, external knowledge sources and discrete reasoning\n",
      "Ehud Karpas, Omri Abend, Yonatan Belinkov, Barak Lenz, Opher Lieber,\n",
      "Nir Ratner, Yoav Shoham, Hoﬁt Bata, Yoav Levine, Kevin Leyton-Brown,\n",
      "Dor Muhlgay, Noam Rozen, Erez Schwartz, Gal Shachaf, Shai\n",
      "Shalev-Shwartz, Amnon Shashua, Moshe Tenenholtz\n",
      "AI21 Labs\n",
      "May 3, 2022\n",
      "Abstract\n",
      "Huge language models (LMs) have ushered in a new era for AI, serving as a gate-\n",
      "way to natural-language-based knowledge tasks. Although an essential element of\n",
      "modern AI, LMs are also inherently limited in a number of ways. We discuss these\n",
      "limitations and how they can be avoided by adopting a systems approach. Con-\n",
      "ceptualizing the challenge as one that involves knowledge and reasoning in addition\n",
      "to linguistic processing, we deﬁne a ﬂexible architecture with multiple neural mod-\n",
      "els, complemented by discrete knowledge and reasoning modules. We describe this\n",
      "neuro-symbolic archi\n"
     ]
    }
   ],
   "source": [
    "## Printing out a sample of the content\n",
    "print(\"Number of Documents Retrieved:\", len(documents))\n",
    "print(f\"Sample of Document 1 Content (Total Length: {len(documents[0].page_content)}):\")\n",
    "print(documents[0].page_content[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8847639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Authors': 'Ehud Karpas, Omri Abend, Yonatan Belinkov, Barak Lenz, Opher '\n",
      "            'Lieber, Nir Ratner, Yoav Shoham, Hofit Bata, Yoav Levine, Kevin '\n",
      "            'Leyton-Brown, Dor Muhlgay, Noam Rozen, Erez Schwartz, Gal '\n",
      "            'Shachaf, Shai Shalev-Shwartz, Amnon Shashua, Moshe Tenenholtz',\n",
      " 'Published': '2022-05-01',\n",
      " 'Summary': 'Huge language models (LMs) have ushered in a new era for AI, '\n",
      "            'serving as a\\n'\n",
      "            'gateway to natural-language-based knowledge tasks. Although an '\n",
      "            'essential\\n'\n",
      "            'element of modern AI, LMs are also inherently limited in a number '\n",
      "            'of ways. We\\n'\n",
      "            'discuss these limitations and how they can be avoided by adopting '\n",
      "            'a systems\\n'\n",
      "            'approach. Conceptualizing the challenge as one that involves '\n",
      "            'knowledge and\\n'\n",
      "            'reasoning in addition to linguistic processing, we define a '\n",
      "            'flexible\\n'\n",
      "            'architecture with multiple neural models, complemented by '\n",
      "            'discrete knowledge\\n'\n",
      "            'and reasoning modules. We describe this neuro-symbolic '\n",
      "            'architecture, dubbed the\\n'\n",
      "            'Modular Reasoning, Knowledge and Language (MRKL, pronounced '\n",
      "            '\"miracle\") system,\\n'\n",
      "            'some of the technical challenges in implementing it, and '\n",
      "            \"Jurassic-X, AI21 Labs'\\n\"\n",
      "            'MRKL system implementation.',\n",
      " 'Title': 'MRKL Systems: A modular, neuro-symbolic architecture that combines '\n",
      "          'large language models, external knowledge sources and discrete '\n",
      "          'reasoning'}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(documents[0].metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e284645",
   "metadata": {},
   "source": [
    "## Transforming Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1945a03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1200,\n",
    "    chunk_overlap=100,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \".\", \";\", \",\", \" \", \"\"],\n",
    ")\n",
    "\n",
    "## Some nice custom preprocessing\n",
    "# documents[0].page_content = documents[0].page_content.replace(\". .\", \"\")\n",
    "docs_split = text_splitter.split_documents(documents)\n",
    "\n",
    "# def include_doc(doc):\n",
    "#     ## Some chunks will be overburdened with useless numerical data, so we'll filter it out\n",
    "#     string = doc.page_content\n",
    "#     if len([l for l in string if l.isalpha()]) < (len(string)//2):\n",
    "#         return False\n",
    "#     return True\n",
    "\n",
    "# docs_split = [doc for doc in docs_split if include_doc(doc)]\n",
    "print(len(docs_split))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8e154ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]  MRKL Systems\n",
      "A modular, neuro-symbolic architecture that combines large language\n",
      "models, external knowledge sources and discrete reasoning\n",
      "Ehud Karpas, Omri Abend, Yonatan Belinkov, Barak Lenz, Opher Lieber,\n",
      "Nir Ratner, Yoav Shoham, Hoﬁt Bata, Yoav Levine, Kevin Leyton-Brown,\n",
      "Dor Muhlgay, Noam Rozen, Erez Schwartz, Gal Shachaf, Shai\n",
      "Shalev-Shwartz, Amnon Shashua, Moshe Tenenholtz\n",
      "AI21 Labs\n",
      "May 3, 2022\n",
      "Abstract\n",
      "Huge language models (LMs) have ushered in a new era for AI, serving as a gate-\n",
      "way to natural-language-based knowledge tasks. Although an essential element of\n",
      "modern AI, LMs are also inherently limited in a number of ways. We discuss these\n",
      "limitations and how they can be avoided by adopting a systems approach. Con-\n",
      "ceptualizing the challenge as one that involves knowledge and reasoning in addition\n",
      "to linguistic processing, we deﬁne a ﬂexible architecture with multiple neural mod-\n",
      "els, complemented by discrete knowledge and reasoning modules. We describe this\n",
      "neuro-symbolic architecture, dubbed the Modular Reasoning, Knowledge and Lan-\n",
      "guage (MRKL, pronounced “miracle”) system, some of the technical challenges in\n",
      "----------------------------------------------------------------\n",
      "[1]  guage (MRKL, pronounced “miracle”) system, some of the technical challenges in\n",
      "implementing it, and Jurassic-X, AI21 Labs’ MRKL system implementation.\n",
      "1\n",
      "Introduction\n",
      "Huge language models (LMs) such as BERT [1], GPT-3 [2], Jurassic-1 [3], PaLM [4],\n",
      "and others [5–9], have taken AI by storm, with the promise of serving as versatile,\n",
      "general-purpose foundations for many applications. Indeed, partly for this reason,\n",
      "they have been rebranded by some as “foundation models” [10]. The term is meant\n",
      "broadly, covering language models as well as models that were trained on more than\n",
      "just text, and although such multimodal models are not the focus of this paper,\n",
      "there’s another reason to take the term “language model” with a grain of salt. While\n",
      "LMs indeed model syntax, and other linguistic elements, their most striking feature\n",
      "is that they model the world, as described by the data on which they were trained.\n",
      "1\n",
      "arXiv:2205.00445v1  [cs.CL]  1 May 2022\n",
      "And so really LMs serve as a textual gateway to the universe of knowledge [11, 12],\n",
      "and perhaps should instead be called “language and knowledge” models.\n",
      "When viewed this way, it becomes clear that, despite their value, current LMs\n",
      "----------------------------------------------------------------\n",
      "[2]  When viewed this way, it becomes clear that, despite their value, current LMs\n",
      "have inherent limitations. While versatile and impressive, the output of even huge\n",
      "LMs is in many cases wrong, and often ridiculously so [13]. Here is a sample output\n",
      "of GPT-3 on some simple queries. (To be clear, this is not a critique of GPT-3 specif-\n",
      "ically, and other LMs — including our own Jurassic-1 — exhibit similar silliness.)\n",
      "For example, LMs can struggle to understand that there are no US cities with\n",
      "more than 20m citizens, that a math teacher is a person, don’t know what today’s\n",
      "date is, nor can they engage in even simple (e.g., mathematical) reasoning.\n",
      "When you look for the root cause, you realize the core limitations of LMs: They\n",
      "don’t have access to all relevant knowledge, and neural models are ill-suited for\n",
      "certain types of calculation. More speciﬁcally:\n",
      "1. Lack of access to current information. Certain data constantly change – the\n",
      "exchange rate between the dollar and the Moroccan Dirham, current COVID\n",
      "numbers, the stock price of AAPL, the weather in Vancouver (OK, not so\n",
      "much), or even the current date. It’s impossible, by their design, for pretrained\n",
      "----------------------------------------------------------------\n",
      "[15]  Table 1 presents our results, sliced by the number of digits, and compared to the\n",
      "results by GPT-3’s approach [2] (as representative of all language models that don’t\n",
      "have access to external calculator), reported on addition. We note that we trained\n",
      "on single-digit operations for all settings while GPT-3 was conditioned on examples\n",
      "with the same number of digits when answering a certain problem. Our results show\n",
      "that despite the fact that training was only done on numbers with a single digit,\n",
      "the model is able to generalize to all numbers of digits explored. This is in stark\n",
      "contrast to the approach of language models which attempt to synthesize arithmetic\n",
      "capabilities from the training data, and as a result display a dramatic decrease in\n",
      "performance as the number of digits increases.\n",
      "Num. digits\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "Addition\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "Multiplication\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.98\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "GPT-3\n",
      "N/A\n",
      "1.0\n",
      "0.804\n",
      "0.255\n",
      "0.093\n",
      "N/A\n",
      "N/A\n",
      "N/A\n",
      "N/A\n",
      "Table 1:\n",
      "Robustness to the number of digits in the operands. Accuracy vs. the\n",
      "number of digits in the test data for a model that was trained only on 1-digit operands\n",
      "(5 + 3, etc.). Results for GPT-3 were taken from [2].\n",
      "----------------------------------------------------------------\n",
      "[-1]  1355.\n",
      "20.\n",
      "Wolfson, T. et al. Break It Down: A Question Understanding Benchmark 2020.\n",
      "https://arxiv.org/abs/2001.11770.\n",
      "21.\n",
      "Lester, B., Al-Rfou, R. & Constant, N. The Power of Scale for Parameter-\n",
      "Eﬃcient Prompt Tuning 2021. https://arxiv.org/abs/2104.08691.\n",
      "19\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in (0, 1, 2, 15, -1):\n",
    "    print(f'[{i}] ', docs_split[i].page_content)\n",
    "    print(\"-\"*64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd766616",
   "metadata": {},
   "source": [
    "## The Document Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0d3c08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain_core.runnables.passthrough import RunnableAssign\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "\n",
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA\n",
    "\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from typing import List\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc2f5b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocumentSummaryBase(BaseModel):\n",
    "    running_summary: str = Field(\"\", description=\"Running description of the document. Do not override; only update!\")\n",
    "    main_ideas: List[str] = Field([], description=\"Most important information from the document (max 3)\")\n",
    "    loose_ends: List[str] = Field([], description=\"Open questions that would be good to incorporate into summary, but that are yet unknown (max 3)\")\n",
    "\n",
    "summary_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", (\n",
    "        \"You are generating a running summary of the document. Make it readable by a technical user.\"\n",
    "        \" After this, the old knowledge base will be replaced by the new one. Make sure a reader can still understand everything.\"\n",
    "        \" Keep it short, but as dense and useful as possible! The information should flow from chunk to (loose ends or main ideas) to running_summary.\"\n",
    "        \" The updated knowledge base keep all of the information from running_summary here: {info_base}.\"\n",
    "    )), ('user', (\n",
    "        \"{format_instructions}. Follow the format precisely, including quotations and commas\\n\\n\"\n",
    "        \"{info_base}\\nWithout losing any of the info, update the knowledge base with the following: {input}\"\n",
    "    ))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a6cb062",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RExtract(pydantic_class, llm, prompt):\n",
    "    '''\n",
    "    Runnable Extraction module\n",
    "    Returns a knowledge dictionary populated by slot-filling extraction\n",
    "    '''\n",
    "    parser = PydanticOutputParser(pydantic_object=pydantic_class)\n",
    "    instruct_merge = RunnableAssign({'format_instructions' : lambda x: parser.get_format_instructions()})\n",
    "    def preparse(string):\n",
    "        if '{' not in string: string = '{' + string\n",
    "        if '}' not in string: string = string + '}'\n",
    "        string = (string\n",
    "            .replace(\"\\\\_\", \"_\")\n",
    "            .replace(\"\\n\", \" \")\n",
    "            .replace(\"\\]\", \"]\")\n",
    "            .replace(\"\\[\", \"[\")\n",
    "        )\n",
    "        # print(string)  ## Good for diagnostics\n",
    "        return string\n",
    "    return instruct_merge | prompt | llm | preparse | parser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed0359e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
